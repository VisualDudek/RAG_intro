{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY=sk-...TBW\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv, dotenv_values\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "def hide_api_key(s):\n",
    "    if len(s) < 6:\n",
    "        return \"Input string must be at least 6 characters long\"\n",
    "    return s[:3] + '...' + s[-3:]\n",
    "\n",
    "dotenv_path = find_dotenv(filename=\".env\", raise_error_if_not_found=True)\n",
    "load_dotenv(dotenv_path, override=True)\n",
    "\n",
    "env_vars = dotenv_values(dotenv_path)\n",
    "for k, v in env_vars.items():\n",
    "    if \"OPENAI_API_KEY\" in k:\n",
    "        print(f\"{k}={hide_api_key(v)}\")\n",
    "    else:\n",
    "        print(f\"{k}={v}\")\n",
    "\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# DEBUG: Print all environment variables\n",
    "# for k, v in os.environ.items():\n",
    "#     print(f\"{k}={v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The common cold is a viral infection, so antibiotics are not effective in treating it. The best way to treat a cold is to get plenty of rest, stay hydrated, and manage symptoms with over-the-counter medications such as decongestants, pain relievers, and cough suppressants. It's also important to practice good hygiene, such as washing your hands frequently and covering your mouth and nose when you cough or sneeze, to prevent spreading the virus to others. If symptoms persist or worsen, it's a good idea to consult with a healthcare provider.\", response_metadata={'token_usage': {'completion_tokens': 114, 'prompt_tokens': 36, 'total_tokens': 150}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e8ecdc7b-8ab0-4f06-b5db-b982f6da681e-0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"You're an assistant knowledgeable about healthcare.\n",
    "        Only answer healthcare-related questions.\"\"\"\n",
    "    ),\n",
    "    HumanMessage(content=\"What is the best way to treat a cold?\"),\n",
    "]\n",
    "\n",
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Blood pressure is the force of blood pushing against the walls of the arteries as the heart pumps blood throughout the body. It is measured in millimeters of mercury (mmHg) and is typically expressed as two numbers, such as 120/80 mmHg. The first number (systolic pressure) represents the pressure in the arteries when the heart beats, while the second number (diastolic pressure) represents the pressure in the arteries when the heart is at rest between beats. High blood pressure, also known as hypertension, can increase the risk of heart disease, stroke, and other health problems.', response_metadata={'token_usage': {'completion_tokens': 123, 'prompt_tokens': 12, 'total_tokens': 135}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8dc3806b-84f1-434d-bf30-4050c49fca8b-0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"What is blood pressure?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Your job is to use patient\\nreviews to answer questions about their experience at a hospital.\\nUse the following context to answer questions. Be as detailed\\nas possible, but don't make up any information that's not\\nfrom the context. If you don't know an answer, say you don't know.\\n\\nI had a great stay!\\n\\nDis anyone have a positive expirence?\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "review_template_str = \"\"\"Your job is to use patient\n",
    "reviews to answer questions about their experience at a hospital.\n",
    "Use the following context to answer questions. Be as detailed\n",
    "as possible, but don't make up any information that's not\n",
    "from the context. If you don't know an answer, say you don't know.\n",
    "\n",
    "{context}\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "review_template = ChatPromptTemplate.from_template(review_template_str)\n",
    "\n",
    "context = \"I had a great stay!\"\n",
    "question = \"Did anyone have a positive expirence?\"\n",
    "\n",
    "review_template.format(context=context, question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(as it is above) `ChatPromptTemplate` assumes the string template is a human message by default.\n",
    "Here is how to change it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"Your job is to use patient\\nreviews to answer questions about their experience at a\\nhospital. Use the following context to answer questions.\\nBe as detailed as possible, but don't make up any information\\nthat's not from the context. If you don't know an answer, say\\nyou don't know.\\n\\nI had a great stay!\\n\"),\n",
       " HumanMessage(content='Did anyone have a positive expirence?')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "\n",
    "review_system_template_str = \"\"\"Your job is to use patient\n",
    "reviews to answer questions about their experience at a\n",
    "hospital. Use the following context to answer questions.\n",
    "Be as detailed as possible, but don't make up any information\n",
    "that's not from the context. If you don't know an answer, say\n",
    "you don't know.\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "review_system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"], template=review_system_template_str\n",
    "    )\n",
    ")\n",
    "\n",
    "review_human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"question\"], template=\"{question}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "messages = [review_system_prompt, review_human_prompt]\n",
    "review_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "context = \"I had a great stay!\"\n",
    "question = \"Did anyone have a positive expirence?\"\n",
    "\n",
    "review_prompt_template.format_messages(context=context, question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCEL (LangChain Expression Language) is the way to glue prompt with model and abstract away all of the internal details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Yes, the patient had a great stay at the hospital, indicating a positive experience.', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 88, 'total_tokens': 105}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-539f4c2e-5682-4d74-aedf-9b7884621f4a-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "review_chain = review_prompt_template | chat_model\n",
    "\n",
    "\n",
    "context = \"I had a great stay!\"\n",
    "question = \"Did anyone have a positive expirence?\"\n",
    "\n",
    "review_chain.invoke({\"context\": context, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can push futher with LCEL pipe example and pass output into parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the patient who left the review had a great stay at the hospital.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "review_chain = review_prompt_template | chat_model | output_parser\n",
    "\n",
    "review_chain.invoke({\"context\": context, \"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
